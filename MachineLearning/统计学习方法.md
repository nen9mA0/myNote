## 第一章

### 统计学习策略

#### 损失函数和风险函数

* 0-1损失函数
  $$
  L(Y, f(X)) = \left\{
  \begin{aligned}
  1, Y \neq f(X)
  \\
  0, Y = f(X)
  \end{aligned}
  \right.
  $$

* 平方损失函数
  $$
  L(Y, f(X)) = (Y - f(X))^2
  $$

* 绝对损失函数
  $$
  L(Y, f(X)) = | Y - f(X) |
  $$

* 对数损失函数
  $$
  L(Y, f(X)) = -logP(Y | X)
  $$

损失函数期望为
$$
R_{exp}(f) = E_P[L(Y, f(X))] = \begin{equation*}

\int_{X * Y} L(y, f(x)) P(x,y) dxdy

\end{equation*}
$$
但显然P(x,y)是无法获知的，因此需要引入下面的概念

#### 经验风险

训练数据集的平均损失称为经验风险
$$
R_{emp}(f) = \frac{1}{N} \sum^N_{i=l} L(y_i, f(x_i))
$$
根据大数定律，当N趋于无穷，$R_{emp} \approx R_{exp}$

#### 经验风险最小化与结构风险最小化

前者认为经验风险最小的就是最优模型。事实上当模型是条件概率分布，损失函数是对数损失函数时这就是极大似然估计

经验风险最小化适用于样本量大的情况

结构风险最小化是在小样本量情况下为防止过拟合提出的
$$
R_{srm}(f) = \frac{1}{N} \sum^N_{i=l} L(y_i, f(x_i)) + \lambda J(f)
$$
J(f)表示模型复杂度，复杂度大的模型J(f)大

当模型是条件概率分布，损失函数是对数损失函数，模型复杂度为模型的先验概率，结构风险最小化等价于最大后验概率估计

### 正则化与交叉验证

用于解决过拟合问题

#### 正则化

即上述的结构风险，正则化即结构风险最小化
$$
min \ \  \frac{1}{N} \sum^N_{i=l} L(y_i, f(x_i)) + \lambda J(f)
$$

#### 交叉验证

##### 简单交叉验证

将数据集拆分为训练集和测试集，在不同参数下用训练集训练模型，选出测试误差最小的模型

##### S折交叉验证

随机将数据集切分成S个**互不相交**的子集，用S-1个子集训练，余下的测试。对可能的S种选择重复进行选出最优

##### 留一交叉验证

当S=N（N为数据集大小）称为留一交叉验证

#### 泛化能力

##### 泛化误差

表示该方法学习到的模型对未知数据的预测能力

若学到的模型是 $\hat f$，则其对未知数据预测的误差为**泛化误差**
$$
R_{exp}(\hat f) = E_P[L(Y, \hat f(X))] = \begin{equation*}

\int_{X * Y} L(y, \hat f(x)) P(x,y) dxdy

\end{equation*}
$$
这个公式与损失函数期望形式一致，不同点在于x和y来自于测试数据集

##### 泛化误差上界

假设训练集$T=\{(x_1,y_1), (x_2,y_2), ... , (x_N,y_N)\}$是从联合概率分布P(X,Y)独立同分布产生的，$X \in R^n, Y \in \{-1, +1\}$，假设空间是函数的有限集合$F=\{f_1, f_2, ... , f_d\}$，设f是F中选取的函数，损失函数是0-1损失，则关于f：
$$
\begin{aligned}
期望风险：& R(f) = E[L(Y, f(X))]
\\
经验风险：& \hat R(f) = \frac{1}{N} \sum^N_{i=1} L(y_i, f(x_i))
\\
经验风险最小化函数：& f_N = \mathop{argmin}\limits_{f \in F} \hat R(f)
\\
f_N泛化能力：& R(f_N) = E[L(Y, f_N(X))]
\end{aligned}
$$
