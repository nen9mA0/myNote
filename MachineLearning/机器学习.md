## 第一章 绪论

### 奥卡姆剃刀

该原则即“若有多个假设与观察一致，则选最简单的那个”

### 归纳偏好

对于不同的学习算法A和B，证明结果的总误差与算法无关

#### NFL定理

假设样本空间$\chi$和假设空间H是离散的，`P(h|X,A)`表示使用算法A基于数据集X产生结果为h的概率，令f为真实数据的分布函数，则A在所有样本上的误差为
$$
E_{ote}(A|X,f) = \sum_h \sum_{x \in \chi-X }P(x) B(h(x) \neq f(x)) P(h|X,A)
$$
B(x)是一个布尔函数，x为真时=1，否则=0

上式可以这样理解，对于样本x，出现的概率为P(x)，对于假设h，出现的概率为P(h|X,A)，若h(x)=f(x)，则没有误差，否则有，因此对于样本x，算法A有P(h|X,A)的概率产生假设h(x)，对于整个样本空间，有`P(x)P(h|X,A)`的概率出现“对于样本x产生预测h”的事件。因此所有的错误预测概率相加即总误差

考虑二分类问题，假设真实目标函数f可以是任何$\chi \rightarrow \{0,1\}$，函数空间为$\{0, 1\}^{|\chi|}$，对所有可能的f按**均匀分布**求误差和
$$
\begin{aligned}\sum_f E_{ote}(A|X,f) &= \sum_f \sum_h \sum_{x \in \chi-X }P(x) B(h(x) \neq f(x)) P(h|X,A)\\&= \sum_{x \in \chi-X }P(x) \sum_f B(h(x) \neq f(x)) \sum_h P(h|X,A)\\&= \sum_{x \in \chi-X }P(x) \frac{1}{2} 2^{|\chi|} \sum_h P(h|X,A)\\&= \frac{1}{2} 2^{|\chi|} \sum_{x \in \chi - X} P(x) \cdot 1\end{aligned}
$$
即，最后的误差与算法A B无关，只与训练集X大小有关

## 第二章 模型评估与选择

### 经验误差与过拟合

在m个样本中有a个样本分类错误

* 错误率  $\frac{a}{m}$
* 精度  $1 - \frac{a}{m}$

训练误差/经验误差：学习器在训练集上的误差

泛化误差：学习器在新样本上的误差

### 评估方法

使用验证集来评估

#### 留出法

将数据集D直接划分为一个训练集S和一个验证集T。划分的时候应尽量保持S和T同分布。一般采用保留类别比例的划分方法，称为分层采样

**缺点**：验证集T本身不参与训练

#### 交叉验证法

将数据集D划分为k个大小相似的互斥子集。每次用1个子集作为验证集，另外k-1个子集作为训练集。这样一共可以进行k次训练和测试

**留一法**是只对于大小为m的数据集D，划分数目k=m，因此每次留下作为验证集的只有一组数据。这种方法的好处是不会引入验证集与训练集分布不一致的情况，坏处是训练次数过多

#### 自助法

上述方法都是通过从数据集D中划分一个验证集来测试，但这样必然引入一些偏差。

自助法对于数据集D直接进行随机采样（与上述方法差别在于被采样一次数据可以重新被采样）。

某个样本在m次采样中都没有被采样到的概率是
$$
(1-\frac{1}{m})^m
$$
若数据集很大
$$
\lim\limits_{m \rightarrow \infty} (1 - \frac{1}{m})^m = \frac{1}{e}
$$
因此采用自助法生成的数据集，平均约有36.8%的数据不会被采样到

### 性能度量

在预测任务中，给定样例集$D={(x_1,y_1), (x_2,y_2), ... , (x_m,y_m)}$

其中y是x的标签，要评估学习器f的性能，就要把预测结果f(x)和y进行比较

#### 误差

常用均方误差
$$
E(f;D) = \frac{1}{m} \sum_{i=1}^m (f(x_i) - y_i)^2
$$
对于数据分布D和概率密度函数p
$$
E(f;D) = \int (f(x) - y)^2 p(x)dx
$$

#### 错误率与精度

错误率
$$
E(f;D) = \frac{1}{m} \sum_{i=1}^m B(f(x_i) \neq y_i)
$$
精度
$$
acc(f;D) = \frac{1}{m} \sum_{i=1}^m B(f(x_i) = y_i) = 1 - E(f;D)
$$
对于数据分布D和概率密度函数p

错误率
$$
E(f;D) = \int B(f(x) \neq y) p(x)dx
$$


精度
$$
acc(f;D) = \int B(f(x) = y) p(x)dx = 1 - E(f;D)
$$

#### 查准率 查全率 F1

以二分类问题为例，预测结果有下面4种

| 真实情况/预测结果 | 正例      | 反例      |
| ----------------- | --------- | --------- |
| 正例              | TP 真正例 | FN 假反例 |
| 反例              | FP 假正例 | TN 真反例 |

**查准率**

真正例与预测正例数之比
$$
P = \frac{TP}{TP + FP}
$$
**查全率**

真正例与实际正例数之比
$$
R = \frac{TP}{TP + FN}
$$
查准率和查全率是一对矛盾的度量，

